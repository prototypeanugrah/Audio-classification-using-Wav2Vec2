{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e4af10",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Importing necessary audio file libraries to convert Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70025ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import os\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547d693",
   "metadata": {},
   "source": [
    "### Wav2Vec2 Automatic Speech Recognition Model\n",
    "\n",
    "Using Transfer Learning by implementing Wav2Vec2 HuggingFace Model. I have used two models, small and large (based on training size of original models by Facebook). <br>\n",
    "I have not created a DeepLearning Neural Network pipeline of my own for this case as our sample size of inputs (9) is very small to train a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ead19",
   "metadata": {},
   "source": [
    "Wav2Vec2 is a speech model that accepts a float array corresponding to the raw waveform of the speech signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cebaa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_small  = \"facebook/wav2vec2-base-960h\" # 360MB # Small model\n",
    "model_name_large  = \"facebook/wav2vec2-large-960h-lv60-self\" # 1.18GB # Large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860a9588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor_small = Wav2Vec2Processor.from_pretrained(model_name_small)\n",
    "model_small = Wav2Vec2ForCTC.from_pretrained(model_name_small)\n",
    "\n",
    "processor_large = Wav2Vec2Processor.from_pretrained(model_name_large)\n",
    "model_large = Wav2Vec2ForCTC.from_pretrained(model_name_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd31b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files :  9\n",
      "['102.wav', '112.wav', '134.wav', '137.wav', '138.wav', '147.wav', '154.wav', '323.wav', '423.wav']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('./3_audio_data/')\n",
    "files = files[:-1]\n",
    "print('Number of audio files : ',len(files))\n",
    "print(files)\n",
    "\n",
    "actual_words = ['one','four','four','one','three','one','five','three','five']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9facc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech to text using small Wav2Vec model\n",
    "\n",
    "def get_transcription_small(audio_path):\n",
    "  # load our wav file\n",
    "    speech, sr = torchaudio.load(audio_path)\n",
    "    speech = speech.squeeze()\n",
    "  # or using librosa\n",
    "  # speech, sr = librosa.load(audio_file, sr=16000)\n",
    "  # resample from whatever the audio sampling rate to 16000\n",
    "    resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "    speech = resampler(speech)\n",
    "  # tokenize our wav\n",
    "    input_values = processor_small(speech, return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"]\n",
    "  # perform inference\n",
    "    logits = model_small(input_values)[\"logits\"]\n",
    "  # use argmax to get the predicted IDs\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "  # decode the IDs to text\n",
    "    transcription = processor_small.decode(predicted_ids[0])\n",
    "    return transcription.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745cdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech to text using Large Wav2Vec model\n",
    "\n",
    "def get_transcription_large(audio_path):\n",
    "  # load our wav file\n",
    "    speech, sr = torchaudio.load(audio_path)\n",
    "    speech = speech.squeeze()\n",
    "  # or using librosa\n",
    "  # speech, sr = librosa.load(audio_file, sr=16000)\n",
    "  # resample from whatever the audio sampling rate to 16000\n",
    "    resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "    speech = resampler(speech)\n",
    "  # tokenize our wav\n",
    "    input_values = processor_large(speech, return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"]\n",
    "  # perform inference\n",
    "    logits = model_large(input_values)[\"logits\"]\n",
    "  # use argmax to get the predicted IDs\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "  # decode the IDs to text\n",
    "    transcription = processor_large.decode(predicted_ids[0])\n",
    "    return transcription.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663252cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proto\\anaconda3\\lib\\site-packages\\transformers\\feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted words on small model:  ['wai', 'faw', 'for', 'an', 'three', 'while yo', 'five', 'three', 'five']\n",
      "Actual words :  ['one', 'four', 'four', 'one', 'three', 'one', 'five', 'three', 'five']\n"
     ]
    }
   ],
   "source": [
    "# Extraccting text from audio using small model\n",
    "\n",
    "transcripts_small = []\n",
    "for ele in files:\n",
    "    trans = get_transcription_small(os.path.join('./3_audio_data/', ele))\n",
    "    transcripts_small.append(trans)\n",
    "    \n",
    "print('Predicted words on small model: ',transcripts_small)\n",
    "print('Actual words : ', actual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20573aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted words on big model:  ['well', 'for', 'for', 'a', 'three', 'wa', 'fim', 'tree', 'five']\n",
      "Actual words :  ['one', 'four', 'four', 'one', 'three', 'one', 'five', 'three', 'five']\n"
     ]
    }
   ],
   "source": [
    "# Extraccting text from audio using large model \n",
    "\n",
    "transcripts_large = []\n",
    "for ele in files:\n",
    "    res = get_transcription_large(os.path.join('./3_audio_data/', ele))\n",
    "    transcripts_large.append(res)\n",
    "    \n",
    "print('Predicted words on big model: ',transcripts_large)\n",
    "print('Actual words : ', actual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0900142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_small</th>\n",
       "      <th>Predicted_large</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wai</td>\n",
       "      <td>well</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faw</td>\n",
       "      <td>for</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>while yo</td>\n",
       "      <td>wa</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>five</td>\n",
       "      <td>fim</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>tree</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted_small Predicted_large Actual\n",
       "0             wai            well    one\n",
       "1             faw             for   four\n",
       "2             for             for   four\n",
       "3              an               a    one\n",
       "4           three           three  three\n",
       "5        while yo              wa    one\n",
       "6            five             fim   five\n",
       "7           three            tree  three\n",
       "8            five            five   five"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataset to compare large and small model's predicted strings from audio files\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "dataset['Predicted_small'] = transcripts_small\n",
    "dataset['Predicted_large'] = transcripts_large\n",
    "dataset['Actual'] = actual_words\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebd95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Jaro similarity between Actual class and predicted values of large and small model\n",
    "\n",
    "import jellyfish # Jellyfish library consists of Phonetic and distance methods to compare two strings\n",
    "# For more info refer here - https://github.com/jamesturk/jellyfish\n",
    "\n",
    "actual_classes = dataset.Actual.unique() # Unique values of actual classes\n",
    "\n",
    "def jaro_similarity_calculator(colname):\n",
    "    jaro_similarity = []\n",
    "    values = []\n",
    "    for i in dataset[colname]:\n",
    "        jar_sim = []\n",
    "        index = 0\n",
    "        for j in actual_classes:\n",
    "            jar_sim.append(jellyfish.jaro_similarity(i, j))\n",
    "            max_sim = max(jar_sim)\n",
    "            index = np.argmax(jar_sim)\n",
    "            vals = actual_classes[index]\n",
    "        jaro_similarity.append(max_sim)\n",
    "        values.append(vals)\n",
    "    return [jaro_similarity,values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac10fb",
   "metadata": {},
   "source": [
    "Jaro Similarity is the measure of similarity between two strings. The value of Jaro distance ranges from 0 to 1. where 1 means the strings are equal and 0 means no similarity between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c1968f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_small</th>\n",
       "      <th>Predicted_large</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Large_JaroSim</th>\n",
       "      <th>Small_JaroSim</th>\n",
       "      <th>Predicted_large_Jaro</th>\n",
       "      <th>Predicted_small_Jaro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wai</td>\n",
       "      <td>well</td>\n",
       "      <td>one</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>one</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faw</td>\n",
       "      <td>for</td>\n",
       "      <td>four</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>four</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>four</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>four</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>while yo</td>\n",
       "      <td>wa</td>\n",
       "      <td>one</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>one</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>five</td>\n",
       "      <td>fim</td>\n",
       "      <td>five</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>tree</td>\n",
       "      <td>three</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted_small Predicted_large Actual  Large_JaroSim  Small_JaroSim  \\\n",
       "0             wai            well    one       0.527778       0.527778   \n",
       "1             faw             for   four       0.916667       0.527778   \n",
       "2             for             for   four       0.916667       0.916667   \n",
       "3              an               a    one       0.000000       0.611111   \n",
       "4           three           three  three       1.000000       1.000000   \n",
       "5        while yo              wa    one       0.000000       0.583333   \n",
       "6            five             fim   five       0.722222       1.000000   \n",
       "7           three            tree  three       0.933333       1.000000   \n",
       "8            five            five   five       1.000000       1.000000   \n",
       "\n",
       "  Predicted_large_Jaro Predicted_small_Jaro  \n",
       "0                  one                 five  \n",
       "1                 four                 four  \n",
       "2                 four                 four  \n",
       "3                  one                  one  \n",
       "4                three                three  \n",
       "5                  one                 five  \n",
       "6                 five                 five  \n",
       "7                three                three  \n",
       "8                 five                 five  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding columns for large and small model after computing Jaro similarity\n",
    "# Also, computing the predicted classes after using Jaro similarity\n",
    "\n",
    "dataset['Large_JaroSim'] = jaro_similarity_calculator('Predicted_large')[0]\n",
    "dataset['Small_JaroSim'] = jaro_similarity_calculator('Predicted_small')[0]\n",
    "dataset['Predicted_large_Jaro'] = jaro_similarity_calculator('Predicted_large')[1]\n",
    "dataset['Predicted_small_Jaro'] = jaro_similarity_calculator('Predicted_small')[1]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5600f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model with Predicted_large_jaro - 100.0 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = dataset[dataset.Predicted_large_Jaro == dataset.Actual].shape[0] / dataset.Actual.shape[0]\n",
    "print('Accuracy of model with Predicted_large_jaro -', accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab64e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model with Predicted_small_jaro - 77.77777777777779 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = dataset[dataset.Predicted_small_Jaro == dataset.Actual].shape[0] / dataset.Actual.shape[0]\n",
    "print('Accuracy of model with Predicted_small_jaro -', accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ce2c2",
   "metadata": {},
   "source": [
    "I have used Jaro similarity criterion to compute the closeness of predicted word to the actual word. <br>\n",
    "We can use Levenshtein distance, Jaro distance, Damerau-Levenshtein distance, etc. as well to find distances between two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b003081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro similarity between  wai  and  one  is  0.0\n",
      "Jaro similarity between  wai  and  four  is  0.0\n",
      "Jaro similarity between  wai  and  three  is  0.0\n",
      "Jaro similarity between  wai  and  five  is  0.5277777777777778\n",
      "Maximum similarity is 0.5277777777777778  with  five \n",
      "\n",
      "Jaro similarity between  faw  and  one  is  0.0\n",
      "Jaro similarity between  faw  and  four  is  0.5277777777777778\n",
      "Jaro similarity between  faw  and  three  is  0.0\n",
      "Jaro similarity between  faw  and  five  is  0.5277777777777778\n",
      "Maximum similarity is 0.5277777777777778  with  four \n",
      "\n",
      "Jaro similarity between  for  and  one  is  0.0\n",
      "Jaro similarity between  for  and  four  is  0.9166666666666666\n",
      "Jaro similarity between  for  and  three  is  0.5111111111111111\n",
      "Jaro similarity between  for  and  five  is  0.5277777777777778\n",
      "Maximum similarity is 0.9166666666666666  with  four \n",
      "\n",
      "Jaro similarity between  an  and  one  is  0.611111111111111\n",
      "Jaro similarity between  an  and  four  is  0.0\n",
      "Jaro similarity between  an  and  three  is  0.0\n",
      "Jaro similarity between  an  and  five  is  0.0\n",
      "Maximum similarity is 0.611111111111111  with  one \n",
      "\n",
      "Jaro similarity between  three  and  one  is  0.5111111111111111\n",
      "Jaro similarity between  three  and  four  is  0.48333333333333334\n",
      "Jaro similarity between  three  and  three  is  1.0\n",
      "Jaro similarity between  three  and  five  is  0.48333333333333334\n",
      "Maximum similarity is 1.0  with  three \n",
      "\n",
      "Jaro similarity between  while yo  and  one  is  0.4861111111111111\n",
      "Jaro similarity between  while yo  and  four  is  0.0\n",
      "Jaro similarity between  while yo  and  three  is  0.5499999999999999\n",
      "Jaro similarity between  while yo  and  five  is  0.5833333333333334\n",
      "Maximum similarity is 0.5833333333333334  with  five \n",
      "\n",
      "Jaro similarity between  five  and  one  is  0.5277777777777778\n",
      "Jaro similarity between  five  and  four  is  0.5\n",
      "Jaro similarity between  five  and  three  is  0.48333333333333334\n",
      "Jaro similarity between  five  and  five  is  1.0\n",
      "Maximum similarity is 1.0  with  five \n",
      "\n",
      "Jaro similarity between  three  and  one  is  0.5111111111111111\n",
      "Jaro similarity between  three  and  four  is  0.48333333333333334\n",
      "Jaro similarity between  three  and  three  is  1.0\n",
      "Jaro similarity between  three  and  five  is  0.48333333333333334\n",
      "Maximum similarity is 1.0  with  three \n",
      "\n",
      "Jaro similarity between  five  and  one  is  0.5277777777777778\n",
      "Jaro similarity between  five  and  four  is  0.5\n",
      "Jaro similarity between  five  and  three  is  0.48333333333333334\n",
      "Jaro similarity between  five  and  five  is  1.0\n",
      "Maximum similarity is 1.0  with  five \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring the process of finding the values obtained in Predicted_large_Jaro and Predicted_small_Jaro\n",
    "\n",
    "import jellyfish\n",
    "\n",
    "actual_classes = dataset.Actual.unique()\n",
    "jaro_similarity = []\n",
    "values = []\n",
    "\n",
    "for i in dataset.Predicted_small:\n",
    "    jar_sim = []\n",
    "    index = 0\n",
    "    for j in actual_classes:\n",
    "        jar_sim.append(jellyfish.jaro_similarity(i, j))\n",
    "        print('Jaro similarity between ',i,' and ',j,' is ',jar_sim[-1])\n",
    "        max_sim = max(jar_sim)\n",
    "        index = np.argmax(jar_sim)\n",
    "        vals = actual_classes[index]\n",
    "    print('Maximum similarity is',max_sim,' with ',vals,'\\n')\n",
    "    jaro_similarity.append(max_sim)\n",
    "    values.append(vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2044a",
   "metadata": {},
   "source": [
    "We see in case of 'faw', we see equal similarity of 'faw' with 'four' and 'five', which is surprising. I expected this to have more inclination towards 'four'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826c9c7",
   "metadata": {},
   "source": [
    "## Using Phonetic encoding to check for similarity of sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "258741dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word soundex metaphone nysiis match_rating_codex\n",
      "0    well    W400        WL    WAL                 WL\n",
      "1     one    O500        ON     ON                 ON\n",
      "2     for    F600        FR    FAR                 FR\n",
      "3    four    F600        FR    FAR                 FR\n",
      "4     for    F600        FR    FAR                 FR\n",
      "5    four    F600        FR    FAR                 FR\n",
      "6       a    A000         A      A                  A\n",
      "7     one    O500        ON     ON                 ON\n",
      "8   three    T600        0R    TRY                THR\n",
      "9   three    T600        0R    TRY                THR\n",
      "10     wa    W000         W      W                  W\n",
      "11    one    O500        ON     ON                 ON\n",
      "12    fim    F500        FM    FAN                 FM\n",
      "13   five    F100        FF    FAV                 FV\n",
      "14   tree    T600        TR    TRY                 TR\n",
      "15  three    T600        0R    TRY                THR\n",
      "16   five    F100        FF    FAV                 FV\n",
      "17   five    F100        FF    FAV                 FV\n"
     ]
    }
   ],
   "source": [
    "from jellyfish import soundex, metaphone, nysiis, match_rating_codex,\\\n",
    "    levenshtein_distance, damerau_levenshtein_distance, hamming_distance,\\\n",
    "    jaro_similarity\n",
    "\n",
    "dataList = [i for tup in zip(transcripts_large,actual_words) for i in tup]\n",
    "\n",
    "sounds_encoding_methods = [soundex, metaphone, nysiis, match_rating_codex]\n",
    "\n",
    "report = pd.DataFrame([dataList]).T\n",
    "report.columns = ['word']\n",
    "for i in sounds_encoding_methods:\n",
    "    report[i.__name__]= report['word'].apply(lambda x: i(x))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c794a",
   "metadata": {},
   "source": [
    "Considering 'wai' and 'one', I expected both of them to have similar phonetic encoding as they both start with a sound of 'w'. <br>\n",
    "But this is not the case in our model. Hence, I have not used phonetics to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ddbe96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7481481481481481\n",
      "0.0\n",
      "0.8518518518518517\n",
      "0.8412698412698413\n"
     ]
    }
   ],
   "source": [
    "# Some examples of jaro_similarity\n",
    "\n",
    "print(jellyfish.jaro_similarity('Jellyfish','jelly'))\n",
    "print(jellyfish.jaro_similarity('Jellyfish','fish'))\n",
    "print(jellyfish.jaro_similarity('Jellyfish','jellyFish'))\n",
    "print(jellyfish.jaro_similarity('Jellyfish','jelfish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ae72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4b92891b7f168ae71d70f9c89a871d1bbd94f4cdbe5a952510d1226adfcba54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
